# Ethics in Tech

## Project Dragonfly:
https://www.vox.com/2018/8/17/17704526/google-dragonfly-censored-search-engine-china

This article peaked my interest because I had been to China on multiple business trips when I worked for Amazon. While I was there I found out firsthand that my Apple news feed did not work. Facebook did not work and internet surfing was extremely limited. After having unfettered access without thinking about it for so many years I was forced to remember what life was like before these apps and habits became almost instinctual. 
On one hand I can see that providing censored internet access could be easily considered unethical, but at the same time by saying that Google shouldn't work with the government at all means that 1.3 billion people are completely shut out of the internet. Is it possible that by gaining a foothold in China by working under the Chinese government's censorship rules means that they progress to a state where they can eventually lift the censorship that they had to operate under previously? If Google doesn't get involved does that open the door for another company (maybe the Chinese government itself) to provide the only search engine available closing the door for any possible inroads by a company from a democratic country to make the change. In my eyes some way to access the internet is better than none. It really isn't a cut and dry decision.
However, I think that the point of the article was really about the desire from workers to for clarity from the company into what decisions it was making and to be able to have an active voice in the process. I do agree that Google was likely looking to profit from dragonfly and that their intentions were not totally alturistic but I'm a firm believer that perfect is the enemy of progress and that the people of China who do not get to elect their government do deserve access to effective search engines and that involvement by Google has a better chance at helping to open China than nothing at all. However if I put myself in the shoes of the employees of Google I see the desire and would also feel strongly about being part of the decision process in how my company should approach this dilemma.    


## Will Democracy Survive Big Data with AI?
https://www.scientificamerican.com/article/will-democracy-survive-big-data-and-artificial-intelligence/
This article written in 2017 is even more poignant after the events on Jan 6, 2021. Where we saw the effects of echo chambers materialize in a violent uprising against our own democracy. While I was watching the events unfold live on the news I was struck by how unreal the whole event felt. In my mind I thought even if we disagree at the end of the day we are all Americans and can agree that we should honor the democratic process. I was horrified by the fact that the people inciting the violence had thought that they we somehow defending America. After reading the news on the investigations I learned that many of these people's beliefs were formed from what they read on twitter and facebook and the practices of tailoring each person's experience based on their interaction with a post results in situations where people only see posts that reflect their own ideas and this creates a situation where people then believe that they are doing the 'right' thing.  
The article describes how companies use big data based on data they collect on us without our permission or an independent ethics board review to make decisions on what to show us or in some cases even decide what our credit limit should be. This knowledge makes me very wary of big data. It's also increasingly more alarming when we see politicians using extremely violent, racist and conspiratorial comments because they are targeting a specific type of voter most likely because they are relying on big data and AI to inform the messages they are projecting. In a way I hope that we can use big data to fight disinformation and the article almost makes me want to get a job at facebook so I can start working on ways to fight it myself from within the company itself. I don't know how I would be able to do it right now, but if there are algorithms that can target bulletproof vest ads to people who looked at a Trump post, then there should be a way to remove posts that spread disinformation about vaccines or voter fraud. Maybe instead of just removing them they could also let a user know when they had interacted with a Russian bot or a post they shared on vaccines causing autisim wasn't based in scientific fact and could result in x number of deaths due to risk of measles outbreak.  






[<-- Back](README.md)